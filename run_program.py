import pandas as pd
from bs4 import BeautifulSoup
from function import Scrap_data, opened_link_chroome
from database import DatabaseHandler
import logging
import time

# Setup logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def scrape_store_details(driver, store_link):
    """Scrape chi tiáº¿t cá»­a hÃ ng tá»« link"""
    try:
        logger.info(f"ğŸ” Äang scrape chi tiáº¿t: {store_link[:50]}...")
        
        driver.get(store_link)
        time.sleep(2)  # Giáº£m thá»i gian chá»
        
        data = BeautifulSoup(driver.page_source, 'html.parser')
        
        # TÃ¬m thÃ´ng tin chi tiáº¿t vá»›i selectors má»›i
        details = {
            'phone': 'Not Found',
            'address': 'Not Found', 
            'website': 'Not Found',
            'plus_code': 'Not Found'
        }
        
        # Debug: In ra táº¥t cáº£ text cÃ³ thá»ƒ
        all_text_elements = data.find_all(['div', 'span', 'a'], class_=lambda x: x and any(cls in str(x) for cls in ['Io6YTe', 'fontBodyMedium', 'fontBodySmall']))
        logger.info(f"ğŸ” TÃ¬m tháº¥y {len(all_text_elements)} text elements")
        
        # TÃ¬m phone - tÃ¬m text cÃ³ sá»‘ Ä‘iá»‡n thoáº¡i
        phone_patterns = [
            r'\+\d{1,3}[\s\-]?\d{1,4}[\s\-]?\d{1,4}[\s\-]?\d{1,4}',  # +62 123 456 789
            r'\d{3,4}[\s\-]?\d{3,4}[\s\-]?\d{3,4}',  # 123 456 789
            r'\(\d{3,4}\)[\s\-]?\d{3,4}[\s\-]?\d{3,4}',  # (123) 456 789
        ]
        
        import re
        for elem in all_text_elements:
            text = elem.get_text().strip()
            if text and len(text) > 5:
                for pattern in phone_patterns:
                    if re.search(pattern, text):
                        details['phone'] = text
                        logger.info(f"ğŸ“ TÃ¬m tháº¥y phone: {text}")
                        break
                if details['phone'] != 'Not Found':
                    break
        
        # TÃ¬m address - tÃ¬m text dÃ i cÃ³ váº» lÃ  Ä‘á»‹a chá»‰
        for elem in all_text_elements:
            text = elem.get_text().strip()
            if (text and len(text) > 20 and len(text) < 200 and 
                not text.startswith(('Phone', 'Website', 'Hours', 'Reviews', 'Rating')) and
                not any(char.isdigit() for char in text[:5]) and
                ('Street' in text or 'Road' in text or 'Avenue' in text or 'Jl.' in text or 'ÄÆ°á»ng' in text)):
                details['address'] = text
                logger.info(f"ğŸ“ TÃ¬m tháº¥y address: {text}")
                break
        
        # TÃ¬m website
        website_links = data.find_all('a', href=True)
        for link in website_links:
            href = link.get('href', '')
            if (href.startswith('http') and 
                'google.com' not in href and 
                'maps.google.com' not in href and
                not href.startswith('https://www.google.com/maps')):
                details['website'] = href
                logger.info(f"ğŸŒ TÃ¬m tháº¥y website: {href}")
                break
        
        # TÃ¬m plus code
        for elem in all_text_elements:
            text = elem.get_text().strip()
            if text and '+' in text and len(text) > 8 and len(text) < 20:
                details['plus_code'] = text
                logger.info(f"ğŸ“ TÃ¬m tháº¥y plus code: {text}")
                break
        
        logger.info(f"âœ… HoÃ n thÃ nh scrape chi tiáº¿t: {details}")
        return details
        
    except Exception as e:
        logger.warning(f"âš ï¸ Lá»—i khi scrape chi tiáº¿t: {e}")
        return {
            'phone': 'Error',
            'address': 'Error',
            'website': 'Error', 
            'plus_code': 'Error'
        }

def get_user_input():
    """Láº¥y input tá»« ngÆ°á»i dÃ¹ng"""
    print("ğŸ” === Google Maps Crawler ===")
    print("Nháº­p thÃ´ng tin tÃ¬m kiáº¿m:")
    
    # Tá»« khÃ³a tÃ¬m kiáº¿m
    search_keyword = input("ğŸ“ Tá»« khÃ³a tÃ¬m kiáº¿m (vÃ­ dá»¥: 'kursus stir mobil', 'bÃ¡nh kem', 'nhÃ  hÃ ng'): ").strip()
    if not search_keyword:
        search_keyword = "kursus stir mobil"  # Default
        print(f"âš ï¸ Sá»­ dá»¥ng tá»« khÃ³a máº·c Ä‘á»‹nh: {search_keyword}")
    
    # Vá»‹ trÃ­ tÃ¬m kiáº¿m
    location = input("ğŸ“ Vá»‹ trÃ­ tÃ¬m kiáº¿m (vÃ­ dá»¥: 'Jakarta', 'Ho Chi Minh City', 'Hanoi'): ").strip()
    if not location:
        location = "Jakarta"  # Default
        print(f"âš ï¸ Sá»­ dá»¥ng vá»‹ trÃ­ máº·c Ä‘á»‹nh: {location}")
    
    # Sá»‘ lÆ°á»£ng cá»­a hÃ ng tá»‘i Ä‘a
    try:
        max_stores = input("ğŸ”¢ Sá»‘ lÆ°á»£ng cá»­a hÃ ng tá»‘i Ä‘a (Enter = khÃ´ng giá»›i háº¡n): ").strip()
        max_stores = int(max_stores) if max_stores else 0
    except ValueError:
        max_stores = 0
        print("âš ï¸ Sá»­ dá»¥ng khÃ´ng giá»›i háº¡n sá»‘ lÆ°á»£ng")
    
    return search_keyword, location, max_stores

def build_search_url(keyword, location):
    """Táº¡o URL tÃ¬m kiáº¿m Google Maps"""
    # Encode keyword vÃ  location
    import urllib.parse
    encoded_keyword = urllib.parse.quote(keyword)
    encoded_location = urllib.parse.quote(location)
    
    # Táº¡o URL tÃ¬m kiáº¿m
    search_url = f"https://www.google.com/maps/search/{encoded_keyword}+in+{encoded_location}"
    return search_url

def main():
    logger.info("ğŸš€ Báº¯t Ä‘áº§u Google Maps Crawler...")
    
    # Láº¥y input tá»« ngÆ°á»i dÃ¹ng
    keyword, location, max_stores = get_user_input()
    
    # Táº¡o URL tÃ¬m kiáº¿m
    search_url = build_search_url(keyword, location)
    logger.info(f"ğŸ” TÃ¬m kiáº¿m: '{keyword}' táº¡i '{location}'")
    logger.info(f"ğŸŒ URL: {search_url}")
    
    # Khá»Ÿi táº¡o database
    db = DatabaseHandler()
    
    # Táº¡o driver
    driver = opened_link_chroome(search_url)
    
    try:
        # Scrape danh sÃ¡ch cá»­a hÃ ng
        logger.info("ğŸ“‹ Äang scrape danh sÃ¡ch cá»­a hÃ ng...")
        df = Scrap_data(driver)
        
        if df.empty:
            logger.warning("âš ï¸ KhÃ´ng tÃ¬m tháº¥y cá»­a hÃ ng nÃ o!")
            return
        
        logger.info(f"âœ… TÃ¬m tháº¥y {len(df)} cá»­a hÃ ng")
        print(f"\nğŸ“Š Danh sÃ¡ch cá»­a hÃ ng:")
        print(df[['nama', 'rating', 'link']].head())
        
        # Giá»›i háº¡n sá»‘ lÆ°á»£ng cá»­a hÃ ng náº¿u cáº§n
        if max_stores > 0 and len(df) > max_stores:
            df = df.head(max_stores)
            logger.info(f"ğŸ”¢ Giá»›i háº¡n sá»‘ lÆ°á»£ng cá»­a hÃ ng: {max_stores}")
        
        # Test vá»›i Ã­t cá»­a hÃ ng trÆ°á»›c
        test_limit = min(5, len(df))  # Chá»‰ test 5 cá»­a hÃ ng Ä‘áº§u tiÃªn
        df_test = df.head(test_limit)
        logger.info(f"ğŸ§ª Test vá»›i {test_limit} cá»­a hÃ ng Ä‘áº§u tiÃªn")
        
        # Scrape chi tiáº¿t tá»«ng cá»­a hÃ ng
        logger.info("ğŸ” Báº¯t Ä‘áº§u scrape chi tiáº¿t tá»«ng cá»­a hÃ ng...")
        results = []
        new_stores = 0
        existing_stores = 0
        
        for index, row in df_test.iterrows():
            try:
                logger.info(f"ğŸ“ Äang xá»­ lÃ½ cá»­a hÃ ng {index+1}/{len(df_test)}: {row['nama'][:30]}...")
                
                # Scrape chi tiáº¿t vá»›i timeout
                try:
                    details = scrape_store_details(driver, row['link'])
                except Exception as scrape_error:
                    logger.warning(f"âš ï¸ Lá»—i scrape chi tiáº¿t: {scrape_error}")
                    details = {
                        'phone': 'Error',
                        'address': 'Error',
                        'website': 'Error',
                        'plus_code': 'Error'
                    }
                
                # Táº¡o káº¿t quáº£
                result = {
                    'id': row['id'],
                    'nama': row['nama'],
                    'rating': row['rating'],
                    'link': row['link'],
                    'phone': details['phone'],
                    'address': details['address'],
                    'website': details['website'],
                    'plus_code': details['plus_code'],
                    'search_keyword': keyword,
                    'search_location': location
                }
                
                results.append(result)
                
                # LÆ°u vÃ o database ngay láº­p tá»©c
                try:
                    success = db.insert_store(result)
                    if success:
                        new_stores += 1
                        logger.info(f"âœ… ÄÃ£ lÆ°u cá»­a hÃ ng má»›i: {result['nama'][:30]}...")
                    else:
                        existing_stores += 1
                        logger.info(f"â­ï¸ Cá»­a hÃ ng Ä‘Ã£ tá»“n táº¡i: {result['nama'][:30]}...")
                except Exception as db_error:
                    logger.warning(f"âš ï¸ Lá»—i lÆ°u database: {db_error}")
                
                logger.info(f"âœ… HoÃ n thÃ nh cá»­a hÃ ng {index+1}")
                
                # Nghá»‰ má»™t chÃºt Ä‘á»ƒ trÃ¡nh bá»‹ block
                time.sleep(1)
                
            except KeyboardInterrupt:
                logger.info("â¹ï¸ NgÆ°á»i dÃ¹ng dá»«ng chÆ°Æ¡ng trÃ¬nh")
            break
        # Hiá»ƒn thá»‹ káº¿t quáº£
        if results:
            kf = pd.DataFrame(results)
            
            # Táº¡o tÃªn file output dá»±a trÃªn keyword vÃ  location
            import re
            safe_keyword = re.sub(r'[^\w\s-]', '', keyword).strip()
            safe_location = re.sub(r'[^\w\s-]', '', location).strip()
            output_file = f"google_maps_{safe_keyword}_{safe_location}.xlsx"
            
            # LÆ°u vÃ o Excel
            kf.to_excel(output_file, index=False)
            
            # Hiá»ƒn thá»‹ thá»‘ng kÃª database
            total_stores = db.get_store_count()
            
            logger.info(f"ğŸ‰ HoÃ n thÃ nh! ÄÃ£ xá»­ lÃ½ {len(results)} cá»­a hÃ ng")
            logger.info(f"ğŸ“Š Cá»­a hÃ ng má»›i: {new_stores}")
            logger.info(f"ğŸ“Š Cá»­a hÃ ng Ä‘Ã£ tá»“n táº¡i: {existing_stores}")
            logger.info(f"ğŸ“Š Tá»•ng sá»‘ cá»­a hÃ ng trong database: {total_stores}")
            
            print(f"\nğŸ“Š Káº¿t quáº£ cuá»‘i cÃ¹ng:")
            print(kf[['nama', 'rating', 'phone', 'address']].head())
            print(f"\nğŸ’¾ File Excel: {output_file}")
            print(f"ğŸ—„ï¸ Database: {total_stores} cá»­a hÃ ng tá»•ng cá»™ng")
            print(f"ğŸ†• Cá»­a hÃ ng má»›i: {new_stores}")
            print(f"ğŸ”„ Cá»­a hÃ ng Ä‘Ã£ tá»“n táº¡i: {existing_stores}")
            
        else:
            logger.warning("âš ï¸ KhÃ´ng cÃ³ káº¿t quáº£ nÃ o Ä‘Æ°á»£c lÆ°u!")
            
    except Exception as e:
        logger.error(f"âŒ Lá»—i nghiÃªm trá»ng: {e}")
        
    finally:
        # ÄÃ³ng driver vÃ  database
        try:
            driver.quit()
            logger.info("ğŸ”š ÄÃ£ Ä‘Ã³ng driver")
        except:
            pass
    
        try:
            db.close()
        except:
            pass
    
if __name__ == "__main__":
    main()